---
title: "Epistemology on Real Networks"
author: "Max Noichl, Ignacio Quintana & Hein Duijf"
institute: ""
date: 2024-6-19

format: 
    revealjs:
        template-partials:
            - title-slide.html
        title-slide-attributes:
            data-background-image: images/background_image_front.png
            data-background-size: cover
            data-background-opacity: "1."

        theme: [default, custom.scss]
        navigation-mode: vertical
        include-in-header:  
            text: |
                <style>
                .center-xy {
                margin: 0;
                position: absolute;
                top: 50%;
                
                -ms-transform: translate(-50%, -50%);
                transform: translate(-50%, -50%);
                width: auto; /* Maintain aspect ratio */
                height: auto; /* Maintain aspect ratio */
                box-sizing: border-box; /* Include padding/border in size */
                max-height: none;
                }
                </style>
        auto-stretch: false
        incremental: true 
bibliography: network_epistemology_playground_bib.bib
# csl: the-journal-of-modern-history.csl
cite-method: citeproc
dependencies:
    - "custom.scss"
controls: true
width: 1400 # 1060
height: 1000 # 700
margin: 0.15 # 1
min-scale: 0.2
max-scale: 1.6
# background-image: "images/background_egg.png"
---




# Outline 

* Intro: Network epistemology
* Robustness
* Artificial network models
* Real networks
* Some conclusions


# Network epistemology
* Traditional epistemology focuses on individual rationality 
    - What is the proper response to evidence?
* Network epistemology can target the structure of communication
    - Which communication *structures* are best?
* Kicked off by @zollmanCommunicationStructureEpistemic2007 who uses agent-based modelling and simulations


# Recap: Zollman (2007)
* Agents (scientist) evaluate two competing methods, with similar, but slightly different quality. (Bandit-problem mirroring clinical trials). They communicate their evidence on a network.
* Agents cease evaluating methods they believe to be inferior.
* Main findings:
    - Less connectivity can lead to more reliable groups – **Community structure matters!**
    - There is a tradeoff between speed of convergence and reliability

#
*"Even beyond the problem of maintaining the division of cognitive labor, this model suggests that in some circumstances there is an unintended benefit from scientists being uninformed about experimental results in their field. This is not universally beneficial, however.*

*In circumstances where speed is very important or where we think that our initial estimates are likely very close to the truth, connected groups of scientist will be more reliable. On the other hand, when we want accuracy above all else, we should prefer communities made up of more isolated individuals."* – @zollmanCommunicationStructureEpistemic2007

# Following these strands in Network Epistemology
* A strand on robustness:
    - Robustness under changes in parameter settings (@rosenstockEpistemicNetworksLess2017), 
    - Robustness under changes in modelling choices (@kummerfeldConservatismScientificState2016; @freyWhatEpistemicFunction2018; @freyRobustnessIdealizationsAgentBased2020)
* A strand on conformity: (@zollmanSocialStructureEffects2010; @mohseniTruthConformityNetworks2021; @weatherallConformityScientificNetworks2021; @fazelpourDiversityTrustConformity2022)
* A strand on epistemically impure agents (including financial interests) (@holmanProblemIntransigentlyBiased2015; @weatherallHowBeatScience2020)
* Our work: Empirically guided robustness tests.

# 
::: {.image-container width=100% fig-align="center"}
![](images/zollman_graph.png){.remove_background  width=100% fig-align="center"}
:::
Main network-types used in @zollmanCommunicationStructureEpistemic2007

# 
::: {.image-container width=100% fig-align="center"}
![](images/rosenstock_n_agents.png){.remove_background  width=100% fig-align="center"}
:::
Convergence as a function of network-size – @rosenstockEpistemicNetworksLess2017


# 
*"As a result, we cannot say with confidence that we expect real world epistemic communities to generally fall under the area of parameter space where the Zollman effect occurs. We are unsure whether they correspond to this area of parameter space, or some other area, or some other models with different assumptions."* – @rosenstockEpistemicNetworksLess2017


<!-- <span class="highlight"> Degree Distribution </span> -->
# {background-color="#ededed" background-image="images/circle_graph_background.png" background-opacity=.5 }
::: {.r-fit-text}
But what are the appropriate 
:::
::: {.r-fit-text}
<span class="highlight">networks</span>  to test for the effect?
:::

#
::: {.r-fit-text}
Approach 1: Artificial Networks
:::

#
![](images/network_comparison.png){width=100% fig-align="center"}

::: {.r-fit-text}
Some candidates for more realistic networks
:::


#
::: {.r-fit-text}
But how to evaluate the influence of specific network structures?
:::
::: {.r-fit-text .fragment}
Rewiring!
:::


#
![](images/watts-strogatz-demo.png){width=100% fig-align="center"}

Changing network-structure through randomization 

(E. g. Watts-Strogatz-graph)



# Parameters {.scrollable .nostretch}

::: {style="font-size: 24pt;"}
| Parameter      | Type/Range                             | Description                                                        |
|----------------|----------------------------------------|--------------------------------------------------------------------|
| Number of Agents       | 11 to 200                              | Number of agents in the network                                    |
| BA-Degree      | 2 to 10                                | Degree for the Barabási-Albert (BA) model       |
| ER-Probability        | 0 to 0.25                       | Probability for  edge creation in the Erdos-Renyi (ER) graph model                    |
| Rewiring probability     | 0 to 1                         | Probability of rewiring in the network generated |
| Uncertainty    | 0.001 to 0.01                          | Probability-difference between the theories. (Smaller: harder problem)                          |
| n-experiments  | 10 to 100                              | Number of experiments to run each round (Smaller: Less information collected)    |
| Network-type   | 'ba', 'sf', 'ws'                       | Type of network ('ba': Barabási-Albert, 'sf': directed Scale-Free, 'ws': Watts-Strogatz) |
| Agent-type | 'bayesian', 'beta' | We currently implement two agent types: The original bayesian one, and a beta-distribution based Thompson-sampler.|
:::

# 

![](images/bayes_agent_BA_graph_dat.png){width=80% fig-align="center"}

**Results: Bayesian-learner & Barabási-Albert:** In nearly all simulations, basically all agents learn the correct method. 

# Model-fit: Bayesian-learner & Barabási-Albert
```{.python}
=============================================== ==========================================================
Distribution:                        NormalDist Effective DoF:                                     19.5321
Link Function:                     IdentityLink Log Likelihood:                               -298574.6004
Number of Samples:                          990 AIC:                                            597190.265
                                                AICc:                                           597191.178
                                                GCV:                                                0.0017
                                                Scale:                                              0.0016
                                                Pseudo R-Squared:                                    0.145
==========================================================================================================
Feature Function                  Lambda               Rank         EDoF         P > x        Sig. Code   
================================= ==================== ============ ============ ============ ============
Probability of Rewiring           [0.6]                6            4.2          7.09e-01                 
Uncertainty Level                 [0.6]                6            3.2          2.88e-02     *           
Number of Experiments             [0.6]                6            3.2          6.98e-01                 
Mean Degree                       [0.6]                6            3.3          1.11e-16     ***         
BA-Degree                         [0.6]                6            2.6          1.11e-16     ***         
Number of Agents                  [0.6]                6            3.0          1.50e-05     ***         
Intercept                                              1            0.0          1.11e-16     ***         
==========================================================================================================
Significance codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```


# 
![](images/bayes_agent_BA_graph_gam.png){width=80% fig-align="center"}

**Predicting Quality:** Messing with the hierarchical-ness of the network (prob-rewiring) doesnt seem to make much difference, when predicting the share of <span class="highlight"> correct agents </span> at convergence.


# 
![](images/bayes_agent_BA_graph_gam_convergence.png){width=80% fig-align="center"}

**Predicting Speed:** Probability of rewiring also doesn't influence convergence-time, which is determined by the usual suspects (problem difficulty, number of experiments, degree)






#
::: {.r-fit-text}
These results are very similar for all tested network-types!
:::
:::{.fragment}
::: {.r-fit-text }
We don't find an reliability
:::
::: {.r-fit-text }
advantage for sparser networks.
:::
:::
:::{.fragment .highlight}
::: {.r-fit-text }
We don't find an influence
:::
::: {.r-fit-text }
of rewiring network-structure.
:::
:::

#
::: {.r-fit-text}
Approach 2: Real Networks
:::

# Motivation:

* There are several examples of sub-optimal processes in the history of science.
* *"The hypothesis that peptic ulcers are caused by bacteria did not originate with Warren and Marshall, it predates their births by more than 60 years. But, unlike other famous cases of anticipation, this theory was the subject of significant scientific scrutiny during that time. To those who have faith in the scientific enterprise, it should come as a surprise that the widespread acceptance of a now well supported theory should take so long."* – @zollmanEpistemicBenefitTransient2010
* Our current Examples: Peptic Ulcer (n= 133403, – 1978) & Perceptron (n= 3519, – 1979)
* Author-based citation-network collected from OpenAlex



# The Perceptron network {background-image="images/perceptron_graph_randomized_p=0.png"}
<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>




# 
![](images/perceptron_graph_randomized_p=0_powerlaw_fit.png){width=50% fig-align="center"}

Degree-distribution of the perceptron-network (n=3519).

# The Perceptron network (randomly rewired) {background-image="images/perceptron_graph_randomized_p=0.2.png"}
<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>

# 
![](images/perceptron_graph_randomized_p=0.2_powerlaw_fit.png){width=50% fig-align="center"}

Degree-distribution after random rewiring (p=.2), moving towards a normal degree distribution. Rewiring does not change the mean degree.



# Results: Perceptron - Quality

![](images/perceptron_bayesagent_share_at_convergence.png){width=100% fig-align="center"}

Share of correctly informed (bayesian) agents at convergence depending on varied parameters. 

# Results: Perceptron - Quality

![](images/perceptron_graph_randomized_partial_dependence_share_corr_agents.png){width=100% fig-align="center"}

Isolated dependencies of the <span class="highlight"> correctness of agents</span> on varied parameters. Probability of rewiring seems to strongly drive outcomes!


# Results: Perceptron - Speed

![](images/perceptron_bayesagent_log_convergence_steps.png){width=100% fig-align="center"}

# Results: Perceptron - Speed

![](images/perceptron_graph_randomized_partial_dependence_convergence_time_log.png){width=100% fig-align="center"}


#
::: {.r-fit-text}
Tentative Results
:::

# 
::: {.r-fit-text}
Using more sophisticated
:::
::: {.r-fit-text}
network-models doesn't end
:::
::: {.r-fit-text}
original robustness worries.
:::
:::{ .fragment .highlight}
::: {.r-fit-text}
But network-structure clearly *does*  matter,
:::
::: {.r-fit-text}
as we find real, suboptimal networks!
:::
:::


# Discussion

*  Why does randomization affect our empirical, but not our artificial networks?
* Are there better network-models that reproduce this effect, e. g. more clustered ones?
* What about other rewiring techniques (e.g. increasing pref. attachement)?
* How to adequately represent empirical networks?
* Vary other aspects of networks – E. g. connectivity (c.f. @zollmanCommunicationStructureEpistemic2007, 3.1) vs. degree-inequality?


<!-- 
# Network epistemology
* Kicked off by Zollman (2007, 2010) who uses agent-based modelling and simulations
* Main findings:
    - Less connectivity can lead to more reliable groups
    - There is a robust tradeoff between speed of convergence and reliability
* The ensuing literature has focused on whether and when high connectivity, convergence speed and conformity lead to epistemically better groups  -->

<!-- # Scale-free networks
* The existing literature typically focuses on three simplistic network structures: the cycle, wheel and complete network [INSERT PICTURES?]
* The epistemic value of modelling and simulations depends heavily on their empirical adequacy
* But, these simplistic network structures are rarely observed in the real world
* Real-world networks are often/virtually always *scale-free*: 
    - their degree distribution follows a power law (which is highly unequal)
* Our focus is on the *degree-equality effect*:
    - whether and when higher levels of degree equality leads to epistemically better groups

[INSERT PICTURE OR EXAMPLE OF A SCALE-FREE NETWORK?]

# Empirically sensitive robustness
* The overall aim of our study is to see whether and when the degree-equality effect is robust in an empirically sensitive way
* We aim to address three challenges:
    - Existing work in network epistemology focuses on small networks (typically up to 10 agents) whereas real scientific networks are much larger
    - Existing work in network epistemology focus on simple network structures even though virtually all empirical networks are scale-free
    - There are few attempts to empirically calibrate theoretical findings on artificial networks towards empirical networks
* We propose a two-pronged analysis by analysing both (a) artificial networks *and* (b) empirical networks -->







<!-- 
# Main points
* There is a significant effect of randomizing, on empirical networks. This is one philosophical conversation.
* There does not seem to be an effect in randomizing, for generated/simulated networks. This is another philosophical conversation.

# Methods
We simulate a very specific philsci scenario, namely when the community has a default theory and there is a competitor entering the game. Also this is tied to the philosophical examples we picked.
We consider randomizing networks as the main method.
We run simulations on randomly generated networks, preferential attachment (but maybe we can quickly run a few more just for completeness) -->
<!-- 

We run simulations on empirical networks.


# Results on Simulated Networks (~ 2 slides)

Show results (pretty plots are valuable here), namely now effect. (We can try a few more simulations here too)
Brief discussion on the fact that the parameter space is too big, and the simulated networks can be very different from real life networks.

# Results on Empirical Networks (~ 5 slides)

Explain the two case studies that we selected, and why.
Show visualizations of the networks, and the loglog plots. Emphasize how unequally distributed they are.
Show pretty plots of the results.
Brief discussion of what might explain the effects, as a segway to the next section.

# Discussion (~5 slides)
Proper discussion on what explains the effects, how robust the results are, and how to move forward with the research question. 
I am not entirely sure what explains the effects.
Proper discussion of the fact that how possibly explanations might be deceiving, and that empirically informed approaches are better.

 -->



<!-- #
![](images/%E2%80%8ESFI%20AGWCSS.%E2%80%8E001.png){width=130% fig-align="center"} -->



<!-- 

# One Precursor

* To the best of our knowledge there is one precursor on the degree equality effect
* Zollman (2007, Sect. 3.1) finds that 
    - the wheel does better than the complete network, which suggests that degree-inequality might be epistemically beneficial. 
    - However, since the cycle does better than the wheel, he concludes that low connectivity (not degree-inequality) produces the epistemic benefits. 
* Zollman (2007, Sect. 3.2) goes on to consider all possible networks of size 6 and finds that degree-inequality is not correlated with reliability and, hence, disconfirms the degree-inequality effect.
* Our results:
    - confirm Zollman’s finding on our artificial networks
    - but disconfirms Zollman’s finding on empirical networks -->




# 

![](images/programming_owl_transparent.png){width=100% fig-align="center"}

<div style="text-align: center;">
<h1>Thank you!</h1>
</div>

# Literature